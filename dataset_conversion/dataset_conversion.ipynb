{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gfileid=\"1uS3Wi68-e8540HtZp8b9v_uhoDyTS8yL\"\n",
    "destination_dir=\"./\"\n",
    "destination_path=\"${destination_dir}dataset.tar.gz\"\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${gfileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${gfileid}\" -o ${destination_path}\n",
    "\n",
    "tar -zxf dataset.tar.gz\n",
    "mv dataset/* .\n",
    "rm -rf dataset.tar.gz cookie dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(path, anno_list):\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(\"\\n\".join(anno_list))\n",
    "def read_file(path):\n",
    "     with open(path, \"r\") as file:\n",
    "        return file.readlines()\n",
    "def yolo_str(c, x, y, w, h):\n",
    "    yolo = [c, x, y, w, h]\n",
    "    return \" \".join([str(y) for y in yolo])\n",
    "\n",
    "def img_to_32_multiplier(img):\n",
    "    \n",
    "    w, h= img.size\n",
    "    padding_right = 0\n",
    "    padding_bottom = 0\n",
    "    if w % 32 != 0:\n",
    "        new_w = math.ceil(w /32) * 32\n",
    "        padding_right = new_w - w\n",
    "    if h % 32 != 0:\n",
    "        new_h = math.ceil(h /32) * 32\n",
    "        padding_bottom = new_h - h\n",
    "    border = (0, 0, padding_right, padding_bottom)\n",
    "    new_img = ImageOps.expand(img, border=border,fill='black')\n",
    "    return new_img \n",
    "\n",
    "\n",
    "def conver_to_new_img(img_path, new_file_suffix=\"_m32.\",save=True):\n",
    "    img = Image.open(img_path)\n",
    "    org_w, org_h = img.size\n",
    "    new_img = img_to_32_multiplier(img)\n",
    "    # Adjust annotations\n",
    "    new_w, new_h = new_img.size\n",
    "    if save:\n",
    "        new_img.save(img_path.split(\".\")[0] + new_file_suffix + img_path.split(\".\")[1])\n",
    "    return new_img, org_w, org_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CARPK_devkit & PUCPR+_devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carpk_to_yolo(text):\n",
    "    attr = [float(i) for i in text.strip().split(\" \")]\n",
    "    cx, cy = (attr[0] + attr[2]) / 2 ,  (attr[1] + attr[3])/2\n",
    "    w, h = attr[2] - attr[0] , attr[3] - attr[1] \n",
    "    return cx, cy, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_suffix = \"_m32.\"\n",
    "folders = [\"CARPK_devkit/data\", \"PUCPR+_devkit/data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    prefix = folder.split(\"_\")[0]\n",
    "    annotations = [anno for anno in os.listdir(os.path.join(folder, \"Annotations\")) if \"m32\" not in img]\n",
    "    imgs = [ img for img in os.listdir(os.path.join(folder, \"Images\"))if \"m32\" not in img]\n",
    "    \n",
    "    imgW, imgH = 1280, 736    \n",
    "    for anno in annotations:\n",
    "        print(anno)\n",
    "        if anno.split(\".\")[0] + \".png\" in imgs:\n",
    "            yolo_list = []\n",
    "            path = os.path.join(folder, \"Annotations\", anno)\n",
    "            with open(path, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "                if len(lines) < 150:\n",
    "                    for line in lines:\n",
    "                        cx, cy, w, h = carpk_to_yolo(line)\n",
    "                        yolo = yolo_str(0, cx/imgW, cy/imgH, w/imgW, h/imgH)\n",
    "                        yolo_list.append(yolo)\n",
    "                    write_to_file(folder + '/Annotations/' + anno.split(\".\")[0] + new_file_suffix + \"txt\", yolo_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Vehicules1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Mapping list:\n",
    "1  car\n",
    "2  truck\n",
    "23  ship -> ignore\n",
    "4  tractor -> ignore\n",
    "5  camping car -> van\n",
    "9  van\n",
    "10 vehicle  -> ignore          \n",
    "11 pick-up -> car\n",
    "31 plane -> ignore\n",
    "```\n",
    "\n",
    "Format:\n",
    "the image ID, the coordinates of the center in the image, the\n",
    "orientation of the vehicle, the 4 coordinates of the 4 corners, the class name, a flag stating\n",
    "if the target is entirely contained in the image, a flag stating if the vehicle is occluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_and_size(row):\n",
    "    \n",
    "    xc, yc = float(row[2]), float(row[3])\n",
    "    x_coors = []\n",
    "    for i in range(5,9):\n",
    "        x_coors.append(float(row[i]))\n",
    "    y_coors = []\n",
    "    for j in range(9,13):\n",
    "        y_coors.append(float(row[j]))\n",
    "    w = max(x_coors) - min(x_coors)\n",
    "    h = max(y_coors) - min(y_coors)\n",
    "    return xc, yc, w, h\n",
    "def vehica_tranform_class(class_no):\n",
    "    if class_no in [1, 11]:\n",
    "        return 0\n",
    "    if class_no in [2]:\n",
    "        return 2\n",
    "    if class_no in [5, 9]:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"Vehicules1024/Annotations1024/\"\n",
    "anno_file = \"annotation1024.txt\"\n",
    "new_anno_file =  \"annotation1024_fixed.txt\"\n",
    "\n",
    "anno_path = os.path.join(folder, new_anno_file)\n",
    "img_w, img_h = 1024, 1024\n",
    "\n",
    "bad_annos = []\n",
    "empty_annos = []\n",
    "df = pd.read_csv(anno_path, sep=' ', header=-1, dtype=str)\n",
    "\n",
    "grouped = df.groupby(0)\n",
    "for name, group in grouped:\n",
    "    if name not in ['00000165', '00000327', '00000364', '00000581', '00000824', '00000839']:\n",
    "        anno_text = name + '_co.txt'\n",
    "        annt_text_path = os.path.join(folder, anno_text)\n",
    "        filtered_group = group[(group[13] == \"1\") & (group[14] == \"0\")]\n",
    "    #     print(len(filtered_group))\n",
    "        annos = []\n",
    "        for row in filtered_group.itertuples():\n",
    "            c = int(row[13])\n",
    "            # remove ship plane tractor vehicle\n",
    "            if c not in [23, 4, 31, 10]:\n",
    "                c = vehica_tranform_class(c)\n",
    "                if c != None:\n",
    "                    xc, yc, w, h = get_location_and_size(row)\n",
    "                    yolo = yolo_str(c,xc/img_w, yc/img_h, w/img_w, h/img_h)\n",
    "                    annos.append(yolo)\n",
    "                else:\n",
    "                    bad_annos.append(name)\n",
    "        if len(annos) > 0:\n",
    "            write_to_file(os.path.join(folder, anno_text), annos)\n",
    "        else: \n",
    "            empty_annos.append(name)\n",
    "\n",
    "for bad in bad_annos:\n",
    "    file_path = \"Vehicules1024/Annotations1024/\" + bad + \"_co.txt\"\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "for e_name in empty_annos:\n",
    "    file_path = \"Vehicules1024/Annotations1024/\" + e_name + \"_co.png\"\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aerial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aerial_convert(img_str):\n",
    "    img_path = os.path.join(path,img_str)\n",
    "    img = Image.open(img_path)\n",
    "    org_w, org_h = img.size\n",
    "\n",
    "    # padding\n",
    "    new_img = img_to_32_multiplier(img)\n",
    "    new_img.save(img_path.split(\".\")[0] + new_file_suffix + img_path.split(\".\")[1])\n",
    "    # Adjust annotations\n",
    "    new_w, new_h = new_img.size\n",
    "    w_ratio, h_ratio = org_w/new_w , org_h / new_h\n",
    "    txt_path = img_path.split(\".\")[0] + \".txt\"\n",
    "    ignore_class = [4]\n",
    "    with open(txt_path, \"r\") as file:\n",
    "        new_annos = []\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            figures = [float(n) for n in line.strip().split()]\n",
    "            if int(figures[0]) not in ignore_class:\n",
    "                class_no = int(figures[0])\n",
    "                xc = figures[1] * w_ratio\n",
    "                yc = figures[2] * h_ratio\n",
    "                w = figures[3] * w_ratio\n",
    "                h = figures[4] * h_ratio\n",
    "                new_annos.append(yolo_str(class_no, xc, yc, w, h))\n",
    "        write_to_file(txt_path.split(\".\")[0] + new_file_suffix + txt_path.split(\".\")[1], new_annos)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"aerial/\"\n",
    "new_file_suffix = \"_m32.\"\n",
    "included_extention = ('jpg', 'bmp', 'png', 'gif')\n",
    "img_list = [ f for f in os.listdir(path) if f.endswith(included_extention)]\n",
    "for img_str in img_list:\n",
    "    aerial_convert(img_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. VisDron2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only consider the bounding boxes that score=1, truncation=0, occlusion=0,1\n",
    "\n",
    "```\n",
    "Mapping list:\n",
    "ignored regions(0)  -> ignore\n",
    "pedestrian(1) -> pedestrian\n",
    "people(2) -> pedestrian\n",
    "bicycle(3) -> cyclist\n",
    "car(4) -> car\n",
    "van(5) -> van\n",
    "tricycle(7) -> cyclist\n",
    "awning-tricycle(8) -> cyclist\n",
    "bus(9) -> bus\n",
    "motor(10) -> ignore\n",
    "others(11) -> ignore\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "Format:\n",
    "\n",
    "<bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<score>,<object_category>,<truncation>,<occlusion>\n",
    "\n",
    "Description:\n",
    " \n",
    " <bbox_left>\t     The x coordinate of the top-left corner of the predicted bounding box\n",
    "\n",
    " <bbox_top>\t     The y coordinate of the top-left corner of the predicted object bounding box\n",
    "\n",
    " <bbox_width>\t     The width in pixels of the predicted object bounding box\n",
    "\n",
    "<bbox_height>\t     The height in pixels of the predicted object bounding box\n",
    "\n",
    "   <score>\t     The score in the DETECTION file indicates the confidence of the predicted bounding box enclosing \n",
    "an object instance. The score in GROUNDTRUTH file is set to 1 or 0. 1 indicates the bounding box is considered in evaluation,while 0 indicates the bounding box will be ignored.\n",
    "                      \n",
    "<object_category>    The object category indicates the type of annotated object, (i.e., ignored regions(0), pedestrian(1), people(2), bicycle(3), car(4), van(5), truck(6), tricycle(7), awning-tricycle(8), bus(9),motor(10), others(11))\n",
    "                      \n",
    "<truncation>\t     The score in the DETECTION result file should be set to the constant -1.The score in the GROUNDTRUTH file indicates the degree of object parts appears outside a frame (i.e., no truncation = 0 (truncation ratio 0%), and partial truncation = 1 (truncation ratio 1% ~ 50%)).\n",
    "                      \n",
    "<occlusion>\t     The score in the DETECTION file should be set to the constant -1. The score in the GROUNDTRUTH file indicates the fraction of objects being occluded (i.e., no occlusion = 0 (occlusion ratio 0%), partial occlusion = 1 (occlusion ratio 1% ~ 50%), and heavy occlusion = 2 (occlusion ratio 50% ~ 100%))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visDrone_transform_class(class_no):\n",
    "    if class_no == 4:\n",
    "        return 0\n",
    "    if class_no == 6:\n",
    "        return 1\n",
    "    if class_no == 9:\n",
    "        return 2\n",
    "    if class_no == 5:\n",
    "        return 3\n",
    "    if class_no in [3, 6, 7, 8]:\n",
    "        return 4\n",
    "    if class_no in [1, 2]:\n",
    "        return 5\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"VisDrone2018-DET-train/\"\n",
    "included_extention = ('jpg', 'bmp', 'png', 'gif')\n",
    "img_names = [ f for f in os.listdir(os.path.join(folder, 'images')) if f.endswith(included_extention)]\n",
    "\n",
    "for img_name in img_names:\n",
    "    print(img_name)\n",
    "    new_file_suffix = \"_m32.\"\n",
    "    img_path = os.path.join(folder, 'images', img_name)\n",
    "    anno_path = os.path.join(folder, 'annotations', img_name.split(\".\")[0] + '.txt')\n",
    "    new_anno_path = anno_path.split(\".\")[0] + new_file_suffix + 'txt'\n",
    "\n",
    "    new_img, org_w, org_h = conver_to_new_img(img_path, new_file_suffix, False)\n",
    "    new_w, new_h = new_img.size\n",
    "    w_ratio, h_ratio = org_w/new_w , org_h / new_h\n",
    "\n",
    "    with open(anno_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        annos = []\n",
    "        for line in lines:\n",
    "            attrs = line.strip().split(\",\")\n",
    "            c = visDrone_transform_class(int(attrs[5]))\n",
    "            if c!= 100 and attrs[4] == \"1\" and attrs[-2] == \"0\" and attrs[-1] in [\"0\",\"1\"]:\n",
    "                w = float(attrs[2])\n",
    "                h = float(attrs[3])\n",
    "                xc = float(attrs[0]) + w/2\n",
    "                yc = float(attrs[1]) + h/2\n",
    "                yolo = yolo_str(c, xc/new_w, yc/new_h, w/new_w, h/new_h)\n",
    "                annos.append(yolo)\n",
    "        write_to_file(new_anno_path, annos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anno_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. UAV-benchmark-M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only consider the bounding boxes where out-of-view=1, occlusion=1,3,4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Mapping list:\n",
    "car(1) -> car\n",
    "truck(2) -> truck\n",
    "bus(3) -> bus\n",
    "\n",
    "\n",
    "Format:\n",
    "\n",
    "<frame_index>,<target_id>,<bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<out-of-view>,<occlusion><object_category>\n",
    "\n",
    "Description:\n",
    "\n",
    "    <frame_index> The frame index of the video frame\n",
    "       \n",
    "    <target_id>\t  In the GROUNDTRUTH file, the identity of the target is used to provide the temporal         \n",
    "                  corresponding relation of the bounding boxes in different frames.\n",
    "\t\t\t\t  \n",
    "    <bbox_left>\t  The x coordinate of the top-left corner of the predicted bounding box\n",
    "\t\n",
    "    <bbox_top>\t  The y coordinate of the top-left corner of the predicted object bounding box\n",
    "\t\n",
    "    <bbox_width>  The width in pixels of the predicted object bounding box\n",
    "\t\n",
    "    <bbox_height> The height in pixels of the predicted object bounding box\n",
    "\t\n",
    "    <out-of-view> The score in the GROUNDTRUTH file indicates the degree of object parts appears outside a frame \n",
    "                   (i.e., 'no-out'= 1,'medium-out' =2,'small-out'=3).\n",
    "                   \n",
    "    <occlusion>\t  The score in the GROUNDTRUTH fileindicates the fraction of objects being occluded.(i.e.,'no-occ'=1,'lagre-occ'=2,'medium-occ'=3,'small-occ'=4).\n",
    "\n",
    "    <object_category> The object category indicates the type of annotated object, (i.e.,car(1), truck(2), bus(3))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uav_transfomr_class(class_no):\n",
    "    return class_no - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"UAV-benchmark-M/\"\n",
    "folder_list = [f for f in os.listdir(folder) if \"M\" in f]\n",
    "anno_path = os.path.join(folder, \"GT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_name in folder_list:\n",
    "    print(folder_name)\n",
    "    anno_file = os.path.join(anno_path, folder_name + \"_gt_whole.txt\")\n",
    "    print(anno_file)\n",
    "    df = pd.read_csv(anno_file, sep=',', header=-1, dtype=str)\n",
    "    grouped = df.groupby(0)\n",
    "    \n",
    "    for name, group in grouped:    \n",
    "        anno_text_name = folder_name + '_img{0:06d}_m32.txt'.format(int(name))\n",
    "        img_name = 'img{0:06d}.jpg'.format(int(name))\n",
    "        img_path = os.path.join(folder, folder_name, img_name)\n",
    "        new_img, _, _, = conver_to_new_img(img_path, new_file_suffix, False)\n",
    "        new_img.save( os.path.join(folder, folder_name,folder_name + '_img{0:06d}_m32.jpg'.format(int(name))))\n",
    "        new_w, new_h = new_img.siz\n",
    "        annos = []\n",
    "        for row in group.itertuples():\n",
    "            if row[-2] in [\"1\", \"4\", \"3\"] and row[-3] == \"1\":\n",
    "                        w = float(row[5])\n",
    "                        h = float(row[6])\n",
    "                        xc = float(row[3]) + w/2\n",
    "                        yc = float(row[4]) + h/2\n",
    "                        c = Uav_transfomr_class(int(row[-1]))\n",
    "                        yolo = yolo_str(c, xc/new_w, yc/new_h, w/new_w, h/new_h)\n",
    "                        annos.append(yolo)\n",
    "            write_to_file(os.path.join(folder, folder_name, anno_text_name), annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Stanford Drone Dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code only converts annotation files  conversion of the videos to images is done separately. Only consider the bounding boxes where occluded=0 , lost=0\n",
    "\n",
    "### Only the video0 of each scene is selected into the final aerial_dataset\n",
    "\n",
    "```\n",
    "Mapping list:\n",
    "Car -> car\n",
    "Cart -> truck\n",
    "Bus -> bus\n",
    "Biker -> cyclist\n",
    "Pedestrian -> pedestrian\n",
    "Skater -> pedestrian\n",
    "\n",
    "Format:\n",
    "\n",
    "1   Track ID. All rows with the same ID belong to the same path.\n",
    "2   xmin. The top left x-coordinate of the bounding box.\n",
    "3   ymin. The top left y-coordinate of the bounding box.\n",
    "4   xmax. The bottom right x-coordinate of the bounding box.\n",
    "5   ymax. The bottom right y-coordinate of the bounding box.\n",
    "6   frame. The frame that this annotation represents.\n",
    "7   lost. If 1, the annotation is outside of the view screen.\n",
    "8   occluded. If 1, the annotation is occluded.\n",
    "9   generated. If 1, the annotation was automatically interpolated.\n",
    "10  label. The label for this annotation, enclosed in quotation marks.\n",
    "11+ attributes. Each column after this is an attribute.\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class number\n",
    "def st_uav_class_transform(cls_name):\n",
    "    if cls_name == 'Car':\n",
    "        return 0\n",
    "    if cls_name == 'Cart':\n",
    "        return 1\n",
    "    if cls_name == 'Bus':\n",
    "        return 2\n",
    "    if cls_name == 'Biker':\n",
    "        return 4\n",
    "    if cls_name in ['Pedestrian', 'Skater'] :\n",
    "        return 5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"st_uav/annotations/\"\n",
    "scences = os.listdir(path)\n",
    "\n",
    "# get all annotation.txt\n",
    "anno_txts = []\n",
    "for s in scences:\n",
    "    if not s.startswith(\".\"):\n",
    "        videos = os.listdir(path + s)\n",
    "        for v in videos:\n",
    "            if not v.startswith(\".\"):\n",
    "                anno_txts.append(os.path.join(path + s + \"/\" + v +\"/annotations.txt\"))\n",
    "                \n",
    "## Convert annotations and split them frame by frame\n",
    "for t in [a for a in anno_txts if \"video0\" in a]:\n",
    "    print(t)\n",
    "    img_path  = t.replace(\"annotations.txt\", \"reference.jpg\")\n",
    "    img_w, img_h = Image.open(img_path).size\n",
    "\n",
    "\n",
    "    df = pd.read_csv(t, sep=' ', header=-1, dtype=str)\n",
    "    grouped = df.groupby(5)\n",
    "    all_annos = []\n",
    "    frames_dir = t.replace(\"annotations.txt\", \"\") + \"frames/\"\n",
    "    \n",
    "    if not os.path.isdir(frames_dir):\n",
    "        os.mkdir(frames_dir)\n",
    "    for name, group in grouped:\n",
    "        frame_name = \"{:06}\".format(int(name) + 1)\n",
    "        frame_annos = []\n",
    "        for row in group.itertuples():\n",
    "            if row[6] != \"1\" and row[7] != \"1\":\n",
    "                xc = (int(row[4]) + int(row[2])) / (2 * img_w)\n",
    "                yc = (int(row[5]) + int(row[3])) / (2 * img_h)\n",
    "                w = (int(row[4]) - int(row[2])) / img_w\n",
    "                h = (int(row[5]) - int(row[3])) / img_h\n",
    "                c = st_uav_class_transform(row[10])\n",
    "                anno = yolo_str(c, xc, yc, w, h)\n",
    "                frame_annos.append(anno)\n",
    "                anno = frame_name + \" \" + anno\n",
    "                all_annos.append(anno)\n",
    "        write_to_file(frames_dir + frame_name + \".txt\", frame_annos)\n",
    "        \n",
    "    write_to_file(t.replace(\"annotations.txt\", \"yolo_annotations_all.txt\"), all_annos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate  train and test set\n",
    "1. Shuffle all the images in aerial_dataset folder and split the them into train and test set\n",
    "2. Save the file path to train.txt and test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '/Users/sonychan/Downloads/'\n",
    "target = \"aerial_dataset/\"\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "split_ratio = 0.8\n",
    "f_list =  [a for a in os.listdir(path + target) if not a.startswith('.') and not a.endswith('.txt')]\n",
    "for f in f_list:\n",
    "    print(f)\n",
    "    file_folder = path + target + f\n",
    "    imgs = [e for e in os.listdir(file_folder) if e.endswith(formats) and not e.startswith('.')]\n",
    "    imgs_path = [ target + f + \"/\" +img for img in imgs]\n",
    "    random.shuffle(imgs_path)\n",
    "    if f == \"uav\":\n",
    "        imgs_path = imgs_path[:int(len(imgs_path) / 3)]\n",
    "    size = len(imgs_path)\n",
    "    print(size)\n",
    "    train = imgs_path[: int(size * split_ratio)]\n",
    "    test = imgs_path[int(size * split_ratio):]\n",
    "    train_list += train\n",
    "    test_list += test\n",
    "write_to_file(\"train.txt\", train_list)\n",
    "write_to_file(\"test.txt\", test_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correctness\n",
    "1. Read train.txt and test.txt.\n",
    "2. Check if all the images in train.txt and test.txt have corresponding anntations.\n",
    "3. Count statistics of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_anno = set()\n",
    "no_img = set()\n",
    "bad_anno = []\n",
    "path  = '/Users/sonychan/Downloads/aerial_dataset/'\n",
    "f_list =  [a for a in os.listdir(path) if not a.startswith('.') and not a.endswith(\".txt\")]\n",
    "counter = 0\n",
    "cata = [0,0,0,0, 0,0]\n",
    "formats = ('jpg', 'png')\n",
    "no_image = 0\n",
    "for f in f_list:\n",
    "    print(f)\n",
    "    file_folder = os.path.join(path, f) \n",
    "    annos = set((e.split(\".\")[0] for e in os.listdir(file_folder) if \".txt\" in e and not e.startswith('.')))\n",
    "    imgs = set((e.split(\".\")[0] for e in os.listdir(file_folder) if e.endswith(formats) and not e.startswith('.')))\n",
    "    has_both = annos.intersection(imgs)\n",
    "    no_anno.union(annos.difference(has_both))\n",
    "    no_img.union(imgs.difference(has_both))\n",
    "    print(\"no_annotation_txt: {}\".format(no_anno))\n",
    "    print(\"no_image_txt: {}\".format(no_img))\n",
    "    for anno in annos:\n",
    "        no_image += 1\n",
    "        with open(file_folder + \"/\" + anno + \".txt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            counter += len(lines)\n",
    "            bad_lines = [line for line in lines if len(line.split(\" \")) != 5]\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    class_no = line.split()[0]\n",
    "                    cata[int(class_no)] += 1\n",
    "                except:\n",
    "                    print(anno)\n",
    "                    print(class_no)\n",
    "                \n",
    "            if len(bad_lines) != 0:\n",
    "                bad_anno.append(anno)\n",
    "print(bad_anno)\n",
    "print(\"Number of images: {}\".format(no_image))\n",
    "print(\"Number of vehicles: {}\".format(counter))\n",
    "print(\"Number of cars: {}\".format(cata[0]))\n",
    "print(\"Number of trucks: {}\".format(cata[1]))\n",
    "print(\"Number of buses: {}\".format(cata[2]))\n",
    "print(\"Number of vans: {}\".format(cata[3]))\n",
    "print(\"Number of Cyclist: {}\".format(cata[4]))\n",
    "print(\"Number of Pedestrian: {}\".format(cata[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
